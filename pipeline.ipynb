{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Please type in the following variables\n",
        "storage_account_name = \"amldbxadls\"     # ADLS account\n",
        "container_name = \"data\"                 # ADLS container, make sure it exists\n",
        "path_to_raw_data = 'nyctlcraw'          # path in ADLS container\n",
        "path_to_cleaned_date = 'nyctlccleaned'  # path in ADLS container\n",
        "datastore_name = 'adlsgen2store'        # Name of Datastore representing ADLS in Azure ML\n",
        "adbcluster_name = 'dbxcluster'          # Name of databricks cluster registered in AML\n",
        "amlcluster_name = 'amlcluster'          # Name of AML cluster\n",
        "\n",
        "experiment_name = 'my-experiment'       # Name of the experiment for tracking in AML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1679884299241
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import azureml.core\n",
        "from azureml.core import Workspace, Experiment, Environment\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.core.runconfig import RunConfiguration, JarLibrary, PyPiLibrary\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.pipeline.core import Pipeline, PipelineData\n",
        "from azureml.pipeline.steps import DatabricksStep, PythonScriptStep\n",
        "from azureml.data.data_reference import DataReference\n",
        "from azureml.data import OutputFileDatasetConfig\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)\n",
        "ws = Workspace.from_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create connections\n",
        "adlsstore = ws.datastores[datastore_name]\n",
        "\n",
        "rawdata = DataReference(datastore=adlsstore, path_on_datastore=\"nyctlcraw\", data_reference_name=\"input\")\n",
        "cleaneddata = DataReference(datastore=adlsstore, path_on_datastore=\"nyctlccleaned\", data_reference_name=\"output\")\n",
        "aggdata = OutputFileDatasetConfig(name=\"output\", destination=(adlsstore, \"nyctlccleaned\")).as_upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the databricks step\n",
        "\n",
        "step1 = DatabricksStep(\n",
        "    name=\"Data Aggregation\",\n",
        "    run_name='Aggregate data and store in cleaned dataset as parquet',\n",
        "    # Inputs and Outputs\n",
        "    inputs=[rawdata], \n",
        "    outputs=[aggdata],\n",
        "    \n",
        "    # Databricks Cluster\n",
        "    compute_target=ws.compute_targets[adbcluster_name],\n",
        "    spark_version='11.3.x-scala2.12', # don't leave blank, default is very old\n",
        "    node_type='Standard_D4A_v4',  # specify if you know what you need, or leave blank\n",
        "    num_workers=1, # for this task 1 or 2 is enough, if data is large, you may want a large cluster\n",
        "    # alternatively, you can use an existing cluster\n",
        "    # existing_cluster_id='',\n",
        "\n",
        "    # Local file address\n",
        "    source_directory='./databricks_step',\n",
        "    python_script_name='main.py',\n",
        "\n",
        "    # Use this option to save the results, when running pipeline without changes to this step\n",
        "    allow_reuse=True,\n",
        "    # you can install any package that you need to use in databricks cluster\n",
        "    pypi_libraries= [PyPiLibrary('azureml-mlflow','')],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the azureml step\n",
        "source_directory = './azureml_step'\n",
        "runconfig = RunConfiguration()\n",
        "runconfig.environment = Environment.from_pip_requirements('myenv', source_directory+'/requirements.txt')\n",
        "\n",
        "step2 = PythonScriptStep(\n",
        "    name='DoSomething',\n",
        "    script_name='main.py',\n",
        "    source_directory=source_directory,\n",
        "    arguments=['--input',aggdata.as_input()],\n",
        "    compute_target=ws.compute_targets[amlcluster_name],\n",
        "    runconfig=runconfig,\n",
        "    allow_reuse=False, \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1679887474708
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create the pipeline and submit\n",
        "\n",
        "pipeline = Pipeline(workspace=ws, steps=[\n",
        "    step1, \n",
        "    # step2,\n",
        "])\n",
        "pipeline_run = Experiment(ws, experiment_name).submit(pipeline)\n",
        "pipeline_run.wait_for_completion()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
